---
layout: post
title: 06 redis配置文件详解
tags:
- Redis
categories: Redis
description: Redis
---

进入Redis的安装包，里面的“redis.conf”就是默认的配置文件，启动Redis Server的时候，可以指定加载某个路径下的配置文件“redis-server [path of configuration file]”。 

<!-- more --> 

默认的配置文件中，首先约定了存储单位： 

*1k => 1000 bytes*

*1kb => 1024 bytes*

*1m => 1000000 bytes*

*1mb => 1024\*1024 bytes*

*1g => 1000000000 bytes*

*1gb => 1024\*1024*1024 bytes*

Redis配置中对单位的大小写不敏感，1GB、1Gb和1gB都是相同的。由此也说明，Redis只支持bytes，不支持bit单位。

Redis支持以“includes”的方式引入其他配置文件，比如：

include/path/to/local.conf

include/path/to/other.conf

需要注意的是，假如多个一个配置项在不同配置文件中都有定义，则以最后一行读入的为准，就是说后面的配置项会覆盖前面的配置项。

### 1 通用配置

```java
# redis 配置文件示例
 
# 当你需要为某个配置项指定内存大小的时候，必须要带上单位，
# 通常的格式就是 1k 5gb 4m 等酱紫：
#
# 1k  => 1000 bytes
# 1kb => 1024 bytes
# 1m  => 1000000 bytes
# 1mb => 1024*1024 bytes
# 1g  => 1000000000 bytes
# 1gb => 1024*1024*1024 bytes
#
# 单位是不区分大小写的，你写 1K 5GB 4M 也行
 
################################## INCLUDES ###################################
 
# 假如说你有一个可用于所有的 redis server 的标准配置模板，
# 但针对某些 server 又需要一些个性化的设置，
# 你可以使用 include 来包含一些其他的配置文件，这对你来说是非常有用的。
#
# 但是要注意哦，include 是不能被 config rewrite 命令改写的
# 由于 redis 总是以最后的加工线作为一个配置指令值，所以你最好是把 include 放在这个文件的最前面，
# 以避免在运行时覆盖配置的改变，相反，你就把它放在后面（外国人真啰嗦）。
#
# include /path/to/local.conf
# include /path/to/other.conf
 
################################ 常用 #####################################
 
# 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。
# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面。
daemonize no
 
# 当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/run/redis.pid 文件里面，
# 但是你可以在这里自己制定它的文件位置。
pidfile /var/run/redis.pid
 
# 监听端口号，默认为 6379，如果你设为 0 ，redis 将不在 socket 上监听任何客户端连接。
port 6379
 
# TCP 监听的最大容纳数量
#
# 在高并发的环境下，你需要把这个值调高以避免客户端连接缓慢的问题。
# Linux 内核会一声不响的把这个值缩小成 /proc/sys/net/core/somaxconn 对应的值，
# 所以你要修改这两个值才能达到你的预期。
tcp-backlog 511
 
# 默认情况下，redis 在 server 上所有有效的网络接口上监听客户端连接。
# 你如果只想让它在一个网络接口上监听，那你就绑定一个IP或者多个IP。
#
# 示例，多个IP用空格隔开:
#
# bind 192.168.1.100 10.0.0.1
# bind 127.0.0.1
 
# 指定 unix socket 的路径。
#
# unixsocket /tmp/redis.sock
# unixsocketperm 755
 
# 指定在一个 client 空闲多少秒之后关闭连接（0 就是不管它）
timeout 0
 
# TCP连接保活策略，可以通过tcp-keepalive配置项来进行设置，单位为秒，假如设置为60秒，则server端会每60秒# 向连接空闲的客户端发起一次ACK请求，以检查客户端是否已经挂掉，对于无响应的客户端则会关闭其连接。所以关闭# 一个连接最长需要120秒的时间。如果设置为0，则不会进行保活检测。
# 推荐一个合理的值就是60秒
tcp-keepalive 0
 
# 定义日志级别。
# 可以是下面的这些值：
# debug (适用于开发或测试阶段)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (适用于生产环境)
# warning (仅仅一些重要的消息被记录)
loglevel notice
 
# 指定日志文件的位置,如果设置为空字符串，则Redis会将日志输出到标准输出。假如在daemon情况下将日志设置为输# 出到标准输出，则日志会被写到/dev/null中
logfile ""
 
# 要想把日志记录到系统日志，就把它改成 yes，
# 也可以可选择性的更新其他的syslog 参数以达到你的要求
# syslog-enabled no
 
# 设置 syslog 的 identity。
# syslog-ident redis
 
# 设置 syslog 的 facility，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值。
# syslog-facility local0
 
# 设置数据库的数目。
# 默认数据库是 DB 0，你可以在每个连接上使用 select <dbid> 命令选择一个不同的数据库，
# 但是 dbid 必须是一个介于 0 到 databasees - 1 之间的值
databases 16
```

### 2 快照配置

```java
################################ 快照 ################################
#
# 存 DB 到磁盘：
#
#   格式：save <间隔时间（秒）> <写入次数>
#
#   根据给定的时间间隔和写入次数将数据保存到磁盘
#
#   下面的例子的意思是：
#   900 秒内如果至少有 1 个 key 的值变化，则保存
#   300 秒内如果至少有 10 个 key 的值变化，则保存
#   60 秒内如果至少有 10000 个 key 的值变化，则保存
#　　
#   注意：你可以注释掉所有的 save 行来停用保存功能。
#   也可以直接一个空字符串来实现停用：
#   save ""
 
save 900 1
save 300 10
save 60 10000
 
# 默认情况下，如果 redis 最后一次的后台保存失败，redis 将停止接受写操作，
# 这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，
# 否则就会没人注意到灾难的发生。
#
# 如果后台保存进程重新启动工作了，redis 也将自动的允许写操作。
#
# 然而你要是安装了靠谱的监控，你可能不希望 redis 这样做，那你就改成 no 好了。
stop-writes-on-bgsave-error yes
 
# 是否在 dump .rdb 数据库的时候使用 LZF 压缩字符串
# 默认都设为 yes
# 如果你希望保存子进程节省点 cpu ，你就设置它为 no ，
# 不过这个数据集可能就会比较大
rdbcompression yes
 
# 在存储快照后，我们还可以让Redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希# # 望获取到最大的性能提升，可以关闭此功能。
rdbchecksum yes
 
# 设置 dump 的文件位置
dbfilename dump.rdb
 
# 工作目录
# 例如上面的 dbfilename 只指定了文件名，
# 但是它会写入到这个目录下。这个配置项一定是个目录，而不能是文件名。
dir ./
```

### 3 主从配置

```java
################################# 主从复制 #################################
 
# 主从复制。使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本。
# 注意这个只需要在 slave 上配置。
#
# slaveof <masterip> <masterport>
 
# 如果 master 需要密码认证，就在这里设置
# masterauth <master-password>
 
# 当一个 slave 与 master 失去联系，或者复制正在进行的时候，
# slave 可能会有两种表现：
#
# 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，
#    或者数据可能是空的在第一次同步的时候
#
# 2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，
#    slave 都将返回一个 "SYNC with master in progress" 的错误，
#
slave-serve-stale-data yes
 
# 你可以配置一个 slave 实体是否接受写入操作。
# 通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，
# 因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。
# 但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。
#
# 从 redis 2.6 版起，默认 slaves 都是只读的。
# 注意：只读的 slaves 没有被设计成在 internet 上暴露给不受信任的客户端。
# 它仅仅是一个针对误用实例的一个保护层。
slave-read-only yes
 
# Slaves 在一个预定义的时间间隔内发送 ping 命令到 server 。
# 你可以改变这个时间间隔。默认为 10 秒。
#
# repl-ping-slave-period 10
 
# 设置主从复制过期时间
# 在主从同步时，可能在这些情况下会有超时发生：
#	（1）以从Redis的角度来看，当有大规模IO传输时。
#	（2）以从Redis的角度来看，当数据传输或PING时，主Redis超时
#	（3）以主Redis的角度来看，在回复从Redis的PING时，从Redis超时
# 用户可以设置上述超时的时限，不过要确保这个时限比repl-ping-slave-period的值要大，否则每次主Redis都会# # 认为从Redis超时
#
# repl-timeout 60
 
# 我们可以控制在主从同步时是否禁用TCP_NODELAY。如果开启TCP_NODELAY，那么主Redis会使用更少的TCP包和更少# 的带宽来向从Redis传输数据。但是这可能会增加一些同步的延迟，大概会达到40毫秒左右。如果关闭了# # # # # # TCP_NODELAY，那么数据同步的延迟时间会降低，但是会消耗更多的带宽。

repl-disable-tcp-nodelay no
 
# 设置主从复制容量大小。这个 backlog 是一个用来在 slaves 被断开连接时
# 存放 slave 数据的 buffer，所以当一个 slave 想要重新连接，通常不希望全部重新同步，
# 只是部分同步就够了，仅仅传递 slave 在断开连接时丢失的这部分数据。
#
# 我们还可以设置同步队列长度。队列长度（backlog)是主Redis中的一个缓冲区，在与从Redis断开连接期间，主# # # Redis会用这个缓冲区来缓存应该发给从Redis的数据。这样的话，当从Redis重新连接上之后，就不必重新全量同步# 数据，只需要同步这部分增量数据即可。
#
# repl-backlog-size 1mb
 
# 如果主Redis等了一段时间之后，还是无法连接到从Redis，那么缓冲队列中的数据将被清理掉。我们可以设置主# # # Redis要等待的时间长度。如果设置为0，则表示永远不清理。默认是1个小时。
#
# repl-backlog-ttl 3600
 
# 当 master 不能正常工作的时候，Redis Sentinel 会从 slaves 中选出一个新的 master，
# 这个值越小，就越会被优先选中，但是如果是 0 ， 那是意味着这个 slave 不可能被选中。

# 我们可以给众多的从Redis设置优先级，在主Redis持续工作不正常的情况，优先级高的从Redis将会升级为主# # # # Redis。而编号越小，优先级越高。比如一个主Redis有三个从Redis，优先级编号分别为10、100、25，那么编号为# # 10的从Redis将会被首先选中升级为主Redis。当优先级被设置为0时，这个从Redis将永远也不会被选中。默认的优# # 先级为100。
#
# 默认优先级为 100。
slave-priority 100
 
# 假如主Redis发现有超过M个从Redis的连接延时大于N秒，那么主Redis就停止接受外来的写请求。这是因为从Redis# # 一般会每秒钟都向主Redis发出PING，而主Redis会记录每一个从Redis最近一次发来PING的时间点，所以主Redis能# 够了解每一个从Redis的运行情况。
#
# min-slaves-to-write 3
# min-slaves-max-lag 10
#
# 上面这个例子表示，假如有大于等于3个从Redis的连接延迟大于10秒，那么主Redis就不再接受外部的写请求。上述# # 两个配置中有一个被置为0，则这个特性将被关闭。默认情况下min-slaves-to-write为0，而min-slaves-max-lag # 为10。
```

### 4 安全配置

```java
################################## 安全 ###################################
 
# 我们可以要求Redis客户端在向Redis-server发送请求之前，先进行密码验证。由于Redis性能非常高，每秒钟可以 # 完成多达15万次的密码尝试，所以最好设置一个足够复杂的密码，否则很容易被黑客破解。
# 
# 设置认证密码
# i
 
# Redis允许我们对Redis指令进行更名，比如将一些比较危险的命令改个名字，避免被误执行。比如可以把CONFIG命 # 令改成一个很复杂的名字，这样可以避免外部的调用，同时还可以满足内部调用的需要：
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52

# 我们甚至可以禁用掉CONFIG命令，那就是把CONFIG的名字改成一个空字符串：
#
# rename-command CONFIG ""
#
# 但需要注意的是，如果使用AOF方式进行数据持久化，或者需要与从Redis进行通信，那么更改指令的名字可能会引起 # 一些问题。
```

### 5 限制配置

```java
################################### 限制 ####################################
 
# 我们可以设置Redis同时可以与多少个客户端进行连接。默认情况下为10000个客户端。当无法设置进程文件句柄限制 # 时，Redis会设置为当前的文件句柄限制值减去32，因为Redis会为自身内部处理逻辑留一些句柄出来。
# 如果达到了此限制，Redis则会拒绝新的连接请求，并且向这些连接请求方发出“max number of clients # #### # reached”以作回应。
#
# 一旦达到最大限制，redis 将关闭所有的新连接
# 并发送一个‘max number of clients reached’的错误。
#
# maxclients 10000
 
# 如果你设置了这个值，当缓存的数据容量达到这个值， redis 将根据你选择的
# eviction 策略来移除一些 keys。
#
# 如果 redis 不能根据策略移除 keys ，或者是策略被设置为 ‘noeviction’，
# redis 将开始响应错误给命令，如 set，lpush 等等，
# 并继续响应只读的命令，如 get
#
# 我们甚至可以设置Redis可以使用的内存量。一旦到达内存使用上限，Redis将会试图移除内部数据，移除规则可以通 # 过maxmemory-policy来指定。

# 如果Redis无法根据移除规则来移除内存中的数据，或者我们设置了“不允许移除”，那么Redis则会针对那些需要申请 # 内存的指令返回错误信息，比如SET、LPUSH等。但是对于无内存申请的指令，仍然会正常响应，比如GET等。
# 
# 最大使用内存
# maxmemory <bytes>
 
# 最大内存策略，你有 5 个选择。
# 
# 需要注意的一点是，如果Redis是主Redis（说明Redis有从Redis），那么在设置内存使用上限时，需要在系统中留 # 出一些内存空间给同步队列缓存，只有在设置的是“不移除”的情况下，才不用考虑这个因素。

# 对于内存移除规则来说，Redis提供了多达6种的移除规则。他们是：
#（1）volatile-lru：使用LRU算法移除过期集合中的key
#（2）allkeys-lru：使用LRU算法移除key
#（3）volatile-random：在过期集合中移除随机的key
#（4）allkeys-random：移除随机的key
#（5）volatile-ttl：移除那些TTL值最小的key，即那些最近才过期的key。
#（6）noeviction：不进行移除。针对写操作，只是返回错误信息。
# 无论使用上述哪一种移除规则，如果没有合适的key可以移除的话，Redis都会针对写请求返回错误信息。
#
# maxmemory-policy noeviction
 
# LRU算法和最小TTL算法都并非是精确的算法，而是估算值。所以可以设置样本的大小。假如Redis默认会检查三个key # 并选择其中LRU的那个，那么可以改变这个key样本的数量。
#
# maxmemory-samples 5
```

### 6 AOF配置

```java
############################## APPEND ONLY MODE ###############################
 
# 默认情况下，Redis会异步的将数据持久化到磁盘。这种模式在大部分应用程序中已被验证是很有效的，但是在一些问 # 题发生时，比如断电，则这种机制可能会导致数分钟的写请求丢失。

# 如上半部分中介绍的，AOF是一种更好的保持数据一致性的方式。即使当服务器断电时，也仅会有1秒钟的写请求丢 # # 失，当Redis进程出现问题且操作系统运行正常时，甚至只会丢失一条写请求。

# 官方建议，AOF机制和RDB机制可以同时使用，不会有任何冲突。
 
appendonly no
 
# 我们还可以设置AOF文件的名称：
 
appendfilename "appendonly.aof"
 
# fsync()调用，用来告诉操作系统立即将缓存的指令写入磁盘。一些操作系统会“立即”进行，而另外一些操作系统则 # 会“尽快”进行。

# Redis支持三种不同的模式：

#（1）no：不调用fsync()。而是让操作系统自行决定sync的时间。这种模式下，Redis的性能会最快。

#（2）always：在每次写请求后都调用fsync()。这种模式下，Redis会相对较慢，但数据最安全。

#（3）everysec：每秒钟调用一次fsync()。这是性能和安全的折衷。

# 默认情况下为everysec。
appendfsync everysec

# appendfsync no
 
# 当fsync方式设置为always或everysec时，如果后台持久化进程需要执行一个很大的磁盘IO操作，那么Redis可能会 # 在fsync()调用时卡住。目前尚未修复这个问题，这是因为即使我们在另一个新的线程中去执行fsync()，也会阻塞住 # 同步写调用。

# 为了缓解这个问题，我们可以使用下面的配置项，这样的话，当BGSAVE或BGWRITEAOF运行时，fsync()在主进程中的 # 调用会被阻止。这意味着当另一路进程正在对AOF文件进行重构时，Redis的持久化功能就失效了，就好像我们设置 # # 了“appendsync none”一样。如果Redis有时延问题，那么可以将下面的选项设置为yes。否则请保持no，因为这是 # 保证数据完整性的最安全的选择。
 
no-appendfsync-on-rewrite no
 
# 我们允许Redis自动重写aof。当aof增长到一定规模时，Redis会隐式调用BGREWRITEAOF来重写log文件，以缩减文 # 件体积。

# Redis是这样工作的：Redis会记录上次重写时的aof大小。假如Redis自启动至今还没有进行过重写，那么启动时aof # 文件的大小会被作为基准值。这个基准值会和当前的aof大小进行比较。如果当前aof大小超出所设置的增长比例，则 # 会触发重写。另外还需要设置一个最小大小，是为了防止在aof很小时就触发重写。
 
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

### 7 LUA脚本配置

```java
################################ LUA SCRIPTING  ###############################
 
# ua脚本的最大运行时间是需要被严格限制的，单位是毫秒：
lua-time-limit 5000
```

### 8 集群设置

```java
################################ REDIS 集群  ###############################
#
# 启用或停用集群
# cluster-enabled yes
 
# 每个集群节点都有一个集群配置文件，该文件是由集群节点来创建和维护的，不能人工参与。每个集群节点需要不同 # 的配置文件，所以需要保证同一个系统下的集群节点没有重名的配置文件，建议以端口号标记配置文件。
#
# cluster-config-file nodes-6379.conf
 
# 当节点超时大于cluster-node-timeout的时候后，就会被认为宕机了，单位为毫秒。
#
# cluster-node-timeout 15000
 
# Redis集群有一种failover（故障转移）机制，即当主Redis宕机之后，会有一个最合适的从Redis充当主Redis。但 # 是，当从Redis的数据“太老”了，与住Redis的标准数据偏差很大，为了保证数据一致性，Redis会放弃failover。判 # 别从Redis的的数据是不是“太老”有两种方法：

#（1）如果有多个从Redis可以接替主Redis的工作，则它们会交换信息，选取“最佳复制偏移”（接受了原主Redis最多的数据同步）的从Redis作为下一任主Redis。

#（2）每个从Redis计算与原主Redis最后一次数据同步的时间，当最短的时间间隔大于某个临界点的时候，集群则放弃failover。

# 方法（2）当中的临界点可以通过配置调节，临界点的计算规则为：

# (node-timeout * slave-validity-factor)+ repl-ping-slave-period

# 如node-timeout为30秒，slave-validity-factor为10秒，repl-ping-slave-period为10秒，当与原主Redis最 # 后一次对话的时间间隔超过310秒的时候，集群就会放弃failover。

# 当slave-validity-factor太大会使一台数据“太老”的从Redis充当主Redis；而slave-validity-factor太小可能 # 会造成找不到合适的从Redis继任。
#
# cluster-slave-validity-factor 10
 
# 考虑一种极端情况，集群有一台主Redis和四台从Redis，从Redis全部挂掉，failover机制有可能造成集群只有主 # # Redis而无从Redis的尴尬境况。为了保证集群的名副其实，可以规定，当从Redis少于某个数量时，拒绝执行 #   # # failover。  
#
# cluster-migration-barrier 1
 
# 默认情况下，当集群检测到某个哈希槽（hash slot）没有被覆盖（没有任何节点为此服务）会停止接受查询服务， # 如果集群部分宕机最终会导致整个集群不可用，当哈希槽重新被全覆盖的时候会自动变为可用。如果希望那些哈希槽 # 被 覆盖的集群节点继续接受查询服务，需要将cluster-require-full-coverage设置为no。
# cluster-require-full-coverage yes
```

### 9 慢日志配置 

```java
################################## SLOW LOG ###################################
 
# Redis慢日志是指一个系统进行日志查询超过了指定的时长。这个时长不包括IO操作，比如与客户端的交互、发送响 # 应内容等，而仅包括实际执行查询命令的时间。

# 针对慢日志可以设置两个参数，一个是执行时长，单位是微秒，另一个是慢日志的长度。当一个新的命令被写入日志 # 时，最老的一条会从命令日志队列中被移除。单位是微秒，即1000000表示一秒。负数则会禁用慢日志功能，而0则表 # 示强制记录每一个命令。
slowlog-log-slower-than 10000
 
# 慢日志最大长度，可以随便填写数值，没有上限，但要注意它会消耗内存。可以使用SLOWLOG RESET来重设这个值。
slowlog-max-len 128
```

### 10 事件通知配置

```java
############################# Event notification ##############################
 
# Redis可以向客户端通知某些事件的发生。

# 例如，键空间（keyspace）时间通知如果开启，一个客户端对Database 0中的“foo”键执行了DEL操作，两条信息会 # 通过Pub/Sub发布出去：

# PUBLISH__keyspace@0__:foo del
# PUBLISH__keyevent@0__:del foo

# 可以选择需要发送哪种类型的通知，每种类型用一个字母代表：
# K     键空间事件,发布到“__keyspace@<db>__ prefix”频道
# E     键事件, 发布到“ __keyevent@<db>__ prefix”频道
# g     通用事件，比如 DEL,EXPIRE, RENAME, ...等操作都属于
# $     String操作
# l     List操作
# s     Set操作
# h     Hash操作
# z     Sorted set操作
# x     过期操作
# e    驱逐操作（因为内存不足数据被删除）
# A    代表“g$lshzxe”的组合, 所以“AKE”可以代表所有事件

# notify-keyspace-events配置以上述的字母组合为参数，举例说明：
#（1）notify-keyspace-events Elg
# 当有List操作或通用操作，发布通知到“ __keyevent@<db>__ prefix”频道
#（2）notify-keyspace-events Ex
# 当有键的过期操作时，发布通知到“__keyevent@0__:expired”频道
# 默认情况下，notify-keyspace-events的参数为空字符串，代表关闭通知。
notify-keyspace-events ""
```

### 11 高级配置

```java
############################### ADVANCED CONFIG ###############################
 
# Hash在条目数量较小的时候会使用一种高效的内存数据结构编码，当超过某个临界点就会采用另一种存储方式，该临 # 界点由下面的两个配置决定：
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
 
# 与Hash类似，较小的List会以一种特殊的编码方式来节省空间，只要List不超过下面的上限：
list-max-ziplist-entries 512
list-max-ziplist-value 64
 
# Set只有在满足下面的条件时才会采用特殊编码方式：Set中存储的恰好都是十进制的整数，而且长度不超过64位（有 # 符号）。数量上限为：
set-max-intset-entries 512
 
# 同样，有序集合也会采用特殊编码来节省空间，只要不超过上限：
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
 
# RedisHyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大 # # 时，计算基数所需的空间总是固定并且很小的。当HyperLogLog用稀疏式表示法时所用内存超过下面的限制，就会转 # 换成稠密式表示，为了更高的内存利用率，官方建议值为3000。
hll-sparse-max-bytes 3000
 
# Redis 在每 100 毫秒时使用 1 毫秒的 CPU时间来对 Redis 的 hash 表进行重新 hash 。当使用场景中有非常严 # 格的实时性需要，不能够接受 Redis 时不时的对请求有 2 毫秒的延迟的话，把这项配置为 no 。

# 如果没有这么严格的实时性要求，可以设置为 yes ，以便能够尽可能快的释放内存。
activerehashing yes
 
# 客户端的输出缓冲区的限制，因为某种原因客户端从服务器读取数据的速度不够快，可用于强制断开连接（一个常见 # 的原因是一个发布 / 订阅客户端消费消息的速度无法赶上生产它们的速度）。

# 可以三种不同客户端的方式进行设置：
#（1）normal -> 正常客户端
#（2）slave -> slave 和 MONITOR 客户端
#（3）pubsub -> 至少订阅了一个 pubsub channel 或 pattern 的客户端

# 每个client-output-buffer-limit 语法 :
# client-output-buffer-limit<class> <hard limit> <soft limit> <soft seconds> 一旦达到硬限制客户端# 会立即断开，或者达到软限制并保持达成的指定秒数（连续）。

# 例如，如果硬限制为 32 兆字节和软限制为 16 兆字节 /10 秒，如果输出缓冲区的大小达到 32 兆字节，客户端将# 会立即断开，客户端达到 16 兆字节和连续超过了限制 10 秒，也将断开连接。

# 默认 normal 客户端不做限制，因为他们在一个请求后未要求时（以推的方式）不接收数据，只有异步客户端可能会# 出现请求数据的速度比它可以读取的速度快的场景。

# 把硬限制和软限制都设置为 0 来禁用该特性

client-output-buffer-limit normal 0 0 0
client-output-buffer-limit slave 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
 
# Redis会按照一定的频率来执行后台任务，比如关闭超时的客户端，清除过期键等。不是所有的任务都会按照相同的频 # 率来执行，但Redis 依照指定的“ Hz ”值来执行检查任务。
hz 10
 
# aof rewrite过程中，是否采取增量文件同步策略，默认为“yes”。 rewrite过程中,每32M数据进行一次文件同步， # 这样可以减少aof大文件写入对磁盘的操作次数。
aof-rewrite-incremental-fsync yes
```





